{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SQUAD-GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-3eYsk-jBDVSCSDftGCkvPCDRzY7fgWH",
      "authorship_tag": "ABX9TyPJg8yQ7X4SkTGCoy08+3HH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarodchristiansen/PythonProjects/blob/master/SQUAD_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLDo-TYuAWAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEp5oLo-JIeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "050aaddd-c056-49f3-930f-944eac6b8bae"
      },
      "source": [
        "!unzip 602944_1082295_compressed_squad_csv_train-squad.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  602944_1082295_compressed_squad_csv_train-squad.csv.zip\n",
            "  inflating: train-squad.csv         \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-d165101dbf16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip 602944_1082295_compressed_squad_csv_train-squad.csv.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD-zMn0XAaAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('train-squad.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjk-aYDlAwwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOGy8v9FJsaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop('answer_start', axis=1, inplace=True)\n",
        "data.drop('id', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVnoQ6r8BUGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = []\n",
        "question = []\n",
        "answer = []\n",
        "\n",
        "for i in data['context']:\n",
        "  context.append(i)\n",
        "\n",
        "for i in data['question']:\n",
        "  question.append(i)\n",
        "\n",
        "for i in data['text']:\n",
        "  answer.append(i)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE6i2yC-C41b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "fec036c6-2475-4bbf-f79e-405db3d9d966"
      },
      "source": [
        "context[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ4nFfd-MRtW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "1f78595d-c222-48da-b522-5973be5049b6"
      },
      "source": [
        "!pip install ordered-set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ordered-set\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/ab/8252360bfe965bba31ec05112b3067bd129ce4800d89e0b85613bc6044f6/ordered-set-4.0.2.tar.gz\n",
            "Building wheels for collected packages: ordered-set\n",
            "  Building wheel for ordered-set (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ordered-set: filename=ordered_set-4.0.2-py2.py3-none-any.whl size=8209 sha256=1ae9011cf6e91222cf5b979a2ef5807afd127ae05c9beffdf47054049d91108a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/c6/9b/651d8a21d59b51a75ab9c070838f9231b8126421bc0569af47\n",
            "Successfully built ordered-set\n",
            "Installing collected packages: ordered-set\n",
            "Successfully installed ordered-set-4.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRHmtYt7MXXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ordered_set import OrderedSet\n",
        "\n",
        "context = list(OrderedSet(context))\n",
        "question = list(OrderedSet(question))\n",
        "answer = list(OrderedSet(answer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw9KiVMPdH4U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "4427a158-0314-49bd-c6a8-d31f99ed5709"
      },
      "source": [
        "!git clone https://github.com/huggingface/transfer-learning-conv-ai\n",
        "!cd transfer-learning-conv-ai\n",
        "!pip install -r requirements.txt\n",
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transfer-learning-conv-ai'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Total 110 (delta 0), reused 0 (delta 0), pack-reused 110\u001b[K\n",
            "Receiving objects: 100% (110/110), 48.83 KiB | 537.00 KiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (47.3.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8g4ucs3hdkP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6d50361-d37f-4770-b4dc-e56b38e94dab"
      },
      "source": [
        "!pip install torch pytorch-ignite transformers==2.5.1 tensorboardX==1.8 tensorflow  # for tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.1+cu101)\n",
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.4.0.post1)\n",
            "Requirement already satisfied: transformers==2.5.1 in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: tensorboardX==1.8 in /usr/local/lib/python3.6/dist-packages (1.8)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (0.5.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (0.0.43)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (1.14.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.8) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.8) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.30.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (0.15.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.1) (1.17.9)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.1) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.1) (0.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (2.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX==1.8) (47.3.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->transformers==2.5.1) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->transformers==2.5.1) (2.8.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5ZStdQ3k8m7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a41f89ba-52ff-4f00-fe4d-46ab5cdd0d41"
      },
      "source": [
        "!python3 transfer-learning-conv-ai/interact.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-11 12:57:56.124531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "INFO:transfer-learning-conv-ai/interact.py:Namespace(dataset_cache='./dataset_cache', dataset_path='', device='cuda', max_history=2, max_length=20, min_length=1, model='gpt2', model_checkpoint='gpt2-medium', no_sample=False, seed=0, temperature=0.7, top_k=0, top_p=0.9)\n",
            "INFO:transfer-learning-conv-ai/interact.py:Get pretrained model and tokenizer\n",
            "INFO:filelock:Lock 140052426464168 acquired on /root/.cache/torch/transformers/f20f05d3ae37c4e3cd56764d48e566ea5adeba153dcee6eb82a18822c9c731ec.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpkqucnh4h\n",
            "Downloading: 100% 1.04M/1.04M [00:00<00:00, 1.86MB/s]\n",
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-vocab.json in cache at /root/.cache/torch/transformers/f20f05d3ae37c4e3cd56764d48e566ea5adeba153dcee6eb82a18822c9c731ec.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/f20f05d3ae37c4e3cd56764d48e566ea5adeba153dcee6eb82a18822c9c731ec.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "INFO:filelock:Lock 140052426464168 released on /root/.cache/torch/transformers/f20f05d3ae37c4e3cd56764d48e566ea5adeba153dcee6eb82a18822c9c731ec.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
            "INFO:filelock:Lock 140052426423768 acquired on /root/.cache/torch/transformers/6d882670c55563617571fe0c97df88626fb5033927b40fc18a8acf98dafd4946.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp0flsdt2l\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 1.22MB/s]\n",
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-merges.txt in cache at /root/.cache/torch/transformers/6d882670c55563617571fe0c97df88626fb5033927b40fc18a8acf98dafd4946.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/6d882670c55563617571fe0c97df88626fb5033927b40fc18a8acf98dafd4946.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "INFO:filelock:Lock 140052426423768 released on /root/.cache/torch/transformers/6d882670c55563617571fe0c97df88626fb5033927b40fc18a8acf98dafd4946.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-vocab.json from cache at /root/.cache/torch/transformers/f20f05d3ae37c4e3cd56764d48e566ea5adeba153dcee6eb82a18822c9c731ec.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-merges.txt from cache at /root/.cache/torch/transformers/6d882670c55563617571fe0c97df88626fb5033927b40fc18a8acf98dafd4946.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "INFO:filelock:Lock 140052426462936 acquired on /root/.cache/torch/transformers/98aa65385e18b0efd17acd8bf64dcdf21406bb0c99c801c2d3c9f6bfd1f48f29.250d6dc755ccb17d19c7c1a7677636683aa35f0f6cb5461b3c0587bc091551a0.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp9dh1kwky\n",
            "Downloading: 100% 718/718 [00:00<00:00, 570kB/s]\n",
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-config.json in cache at /root/.cache/torch/transformers/98aa65385e18b0efd17acd8bf64dcdf21406bb0c99c801c2d3c9f6bfd1f48f29.250d6dc755ccb17d19c7c1a7677636683aa35f0f6cb5461b3c0587bc091551a0\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/98aa65385e18b0efd17acd8bf64dcdf21406bb0c99c801c2d3c9f6bfd1f48f29.250d6dc755ccb17d19c7c1a7677636683aa35f0f6cb5461b3c0587bc091551a0\n",
            "INFO:filelock:Lock 140052426462936 released on /root/.cache/torch/transformers/98aa65385e18b0efd17acd8bf64dcdf21406bb0c99c801c2d3c9f6bfd1f48f29.250d6dc755ccb17d19c7c1a7677636683aa35f0f6cb5461b3c0587bc091551a0.lock\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-config.json from cache at /root/.cache/torch/transformers/98aa65385e18b0efd17acd8bf64dcdf21406bb0c99c801c2d3c9f6bfd1f48f29.250d6dc755ccb17d19c7c1a7677636683aa35f0f6cb5461b3c0587bc091551a0\n",
            "INFO:transformers.configuration_utils:Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "INFO:filelock:Lock 140052275649224 acquired on /root/.cache/torch/transformers/4b337a4f3b7d3e1518f799e238af607498c02938a3390152aaec7d4dabca5a02.8769029be4f66a5ae1055eefdd1d11621b901d510654266b8681719fff492d6e.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpm6lsur2q\n",
            "Downloading: 100% 1.52G/1.52G [01:05<00:00, 23.3MB/s]\n",
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-pytorch_model.bin in cache at /root/.cache/torch/transformers/4b337a4f3b7d3e1518f799e238af607498c02938a3390152aaec7d4dabca5a02.8769029be4f66a5ae1055eefdd1d11621b901d510654266b8681719fff492d6e\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/4b337a4f3b7d3e1518f799e238af607498c02938a3390152aaec7d4dabca5a02.8769029be4f66a5ae1055eefdd1d11621b901d510654266b8681719fff492d6e\n",
            "INFO:filelock:Lock 140052275649224 released on /root/.cache/torch/transformers/4b337a4f3b7d3e1518f799e238af607498c02938a3390152aaec7d4dabca5a02.8769029be4f66a5ae1055eefdd1d11621b901d510654266b8681719fff492d6e.lock\n",
            "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-pytorch_model.bin from cache at /root/.cache/torch/transformers/4b337a4f3b7d3e1518f799e238af607498c02938a3390152aaec7d4dabca5a02.8769029be4f66a5ae1055eefdd1d11621b901d510654266b8681719fff492d6e\n",
            "INFO:transformers.tokenization_utils:Adding <bos> to the vocabulary\n",
            "INFO:transformers.tokenization_utils:Assigning <bos> to the bos_token key of the tokenizer\n",
            "INFO:transformers.tokenization_utils:Adding <eos> to the vocabulary\n",
            "INFO:transformers.tokenization_utils:Assigning <eos> to the eos_token key of the tokenizer\n",
            "INFO:transformers.tokenization_utils:Adding <pad> to the vocabulary\n",
            "INFO:transformers.tokenization_utils:Assigning <pad> to the pad_token key of the tokenizer\n",
            "INFO:transformers.tokenization_utils:Adding <speaker1> to the vocabulary\n",
            "INFO:transformers.tokenization_utils:Adding <speaker2> to the vocabulary\n",
            "INFO:transformers.tokenization_utils:Assigning ['<speaker1>', '<speaker2>'] to the additional_special_tokens key of the tokenizer\n",
            "INFO:transfer-learning-conv-ai/interact.py:Sample a personality\n",
            "INFO:/content/transfer-learning-conv-ai/utils.py:Download dataset from https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json\n",
            "INFO:filelock:Lock 140052275649168 acquired on /root/.cache/torch/transformers/a6af0e86c91c9dc9b342b96c59adf0d1a4a7dc602d94b01ad47e0bfd19266632.bb42905dd6e1098e87c24845469ee12018cfd142e10fcc50f97b28e002a9ac02.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp9x3olg2l\n",
            "Downloading: 100% 210M/210M [00:08<00:00, 23.9MB/s]\n",
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json in cache at /root/.cache/torch/transformers/a6af0e86c91c9dc9b342b96c59adf0d1a4a7dc602d94b01ad47e0bfd19266632.bb42905dd6e1098e87c24845469ee12018cfd142e10fcc50f97b28e002a9ac02\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/a6af0e86c91c9dc9b342b96c59adf0d1a4a7dc602d94b01ad47e0bfd19266632.bb42905dd6e1098e87c24845469ee12018cfd142e10fcc50f97b28e002a9ac02\n",
            "INFO:filelock:Lock 140052275649168 released on /root/.cache/torch/transformers/a6af0e86c91c9dc9b342b96c59adf0d1a4a7dc602d94b01ad47e0bfd19266632.bb42905dd6e1098e87c24845469ee12018cfd142e10fcc50f97b28e002a9ac02.lock\n",
            "INFO:/content/transfer-learning-conv-ai/utils.py:Tokenize and encode the dataset\n",
            "Hello\n",
            "INFO:transfer-learning-conv-ai/interact.py:Selected personality: one of my favorite hobbies is gaming.i enjoy visiting national parks.i currently work in an office job.i enjoy running.my favorite color is green.\n",
            ">>> transfer-learning-conv-ai/interact.py:80: UserWarning: Warning: model generating special token with probability 1.\n",
            "  warnings.warn(\"Warning: model generating special token with probability 1.\")\n",
            "\n",
            ">>> Hello\n",
            "\n",
            ">>> How are you?\n",
            "\n",
            ">>> nah bruh?\n",
            "\n",
            ">>> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb6lNWxiHccs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "outputId": "51baf787-45f4-43b3-c046-94e6f86f2e9b"
      },
      "source": [
        "!pip install transformers==2.8.0\n",
        "!pip install torch==1.4.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 22.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 6.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.5.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.14.9)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.1.91)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.15.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.17.9)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->transformers==2.8.0) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->transformers==2.8.0) (0.15.2)\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 2.5.1\n",
            "    Uninstalling transformers-2.5.1:\n",
            "      Successfully uninstalled transformers-2.5.1\n",
            "Successfully installed transformers-2.8.0\n",
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 21kB/s \n",
            "\u001b[31mERROR: torchvision 0.6.1+cu101 has requirement torch==1.5.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "Successfully installed torch-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-hKvMBhA1ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-medium\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey5Vx-0EBgfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "afbd17e3-f180-458b-f9c4-43d25ae643f0"
      },
      "source": [
        "sentence_list = [\n",
        "    \"Hi, how are you?.\",\n",
        "]\n",
        "\n",
        "\n",
        "all_sentences_string =\"\"\n",
        "for sentence in sentence_list:\n",
        "    all_sentences_string = all_sentences_string+sentence+tokenizer.eos_token\n",
        "    \n",
        "print (\"All sentences concatenated with EOS token:\\n\")\n",
        "print (all_sentences_string)\n",
        "\n",
        "tokenized_all_sentences_string = tokenizer.encode(all_sentences_string, return_tensors='pt')\n",
        "reply_predicted =  model.generate(tokenized_all_sentences_string, max_length=1000)\n",
        "prefix_length =  tokenized_all_sentences_string.shape[-1]\n",
        "\n",
        "decoded_reply_predicted_with_input = tokenizer.decode(reply_predicted[0], skip_special_tokens=True)\n",
        "decoded_reply_predicted = tokenizer.decode(reply_predicted[:,prefix_length:][0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "print (\"\\n\\nPredicted reply along with initial input: \")\n",
        "print (decoded_reply_predicted_with_input)\n",
        "\n",
        "print (\"\\n\\nPredicted reply: \")\n",
        "print (decoded_reply_predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All sentences concatenated with EOS token:\n",
            "\n",
            "Hi, how are you?.<|endoftext|>\n",
            "\n",
            "\n",
            "Predicted reply along with initial input: \n",
            "Hi, how are you?.I'm good, how are you?\n",
            "\n",
            "\n",
            "Predicted reply: \n",
            "I'm good, how are you?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7sW58KFB-lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}